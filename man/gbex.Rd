% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/1. gradient_boosting_functions.R
\name{gbex}
\alias{gbex}
\title{GPD boosting}
\usage{
gbex(y, X, B = 180, lambda = c(0.025, 0.0025), depth = c(2, 2),
  min_leaf_size = c(30, 30), sf = 0.5, alpha = 0, silent = F)
}
\arguments{
\item{y}{Response variables (vector of length n)}

\item{X}{Covariate matrix (matrix of dimension (n x d))}

\item{B}{Number of gradient boosting steps}

\item{lambda}{learning rate for the scale and shape parameter}

\item{depth}{Maximum depth of the trees}

\item{sf}{sample fraction used for fitting the trees}

\item{alpha}{the power for power divergence (default alpha = 0 meaning maximum likelihood is used)}

\item{silent}{boolean indicating whether progress during fitting procedure should be printed.}
}
\value{
gbex returns an object of class "gbex" which contains the following components:
\item{theta}{Data frame with the estimated gamma and sigma parameter for each observation}
\item{dev}{Numeric with deviance of model}
\item{trees_sigma}{List with gradient_tree objects for sigma}
\item{trees_gamma}{List with gradient_tree objects for gamma}
\item{lambda}{Numeric with the learining rate of sigma and gamma}
\item{B}{Numeric with number of trees}
\item{depth}{Numeric with maximum tree depth for sigma and gamma}
\item{alpha}{Power divergence parameter used}
}
\description{
Estimate the Generalized Pareto distribution conditional on covariates using a boosting procedure.
}
